\documentclass[../main.tex]{subfiles}

\begin{document}

\chapter{代码主体结构}
\vspace{-2cm}

在本章节中，我们将对 BasicSR 代码框架进行一个整体介绍，主要包括以下内容：整体框架 (第\ref{code_structure:overview}小节)、配置文件 (第\ref{code_structure:config}小节)、注册器机制 (第\ref{code_structure:register}小节)、数据 (第\ref{code_structure:data}小节)、网络结构 (第\ref{code_structure:arch}小节)、模型 (第\ref{code_structure:model}小节)、损失函数 (第\ref{code_structure:loss}小节)、训练 (第\ref{code_structure:training}小节)、算子 (第\ref{code_structure:ops}小节) 等。通过阅读本章，你将对 BasicSR 有进一步的认识，理解其模块之间的相互关系、以及模块内部的核心工作原理。但我们不对具体函数和代码做具体介绍。如果需要具体函数和代码的介绍，请查阅 BasicSR 的在线 API 文档 (\url{https://basicsr.readthedocs.io/en/latest/})。

% ------------------------------------------------------------------------------
\section{整体框架} \label{code_structure:overview}
对于基于深度学习的算法框架，其核心的组成部分包括：\textbf{数据、模型、损失函数、训练}。BasicSR 框架也是大致根据以上部分撰写而成的。下图概括了 BasicSR 的整体组成框架：

\begin{figure}[htbp]
    \begin{center}
        \includegraphics[width=1\linewidth]{figures/main_framework.pdf}
    \end{center}
    \caption{BasicSR 代码整体框架}
    \label{fig:main_framework}
\end{figure}

\begin{itemize}
    \item 数据 (Data)：这个部分主要定义了 Dataset 和 Data Loader 文件, 放在了 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/data}{data} 目录下。Dataset 用于读取和预处理数据，包括图像读取、归一化 (normalization)、数据增强 (augmentation) 以及封装为 PyTorch Tensor 等。同时，我们也提供了一些辅助函数，帮助使用者自定义自己的数据预处理功能，例如图像色彩空间转换、常用 MATLAB 函数的 Python 版本、常用的图像退化模型 (degradation model) 等。详细说明参见章节\ref{code_structure:data}：\nameref{code_structure:data}。

    \item 模型 (Model)：在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/models}{models} 目录下，我们提供了常用的模型文件。这些模型文件主要用于定义网络结构与初始化、输入输出数据、一次 forward 的训练过程、保存加载模型等。在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/archs}{archs} 目录下，我们提供了常用的网络结构模型文件，包括 SRResNet、ESRGAN、RCAN、SwinIR、EDVR、BasicVSR 等。在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/losses}{losses} 文件夹中，我们提供了常用的损失函数，例如 L1/L2 loss、perceptual loss、GAN loss 等。详细说明参见章节\ref{code_structure:arch}：\nameref{code_structure:arch}、章节\ref{code_structure:model}：\nameref{code_structure:model}、章节\ref{code_structure:loss}：\nameref{code_structure:loss}。

    \item 配置 (Option)：配置文件放到 \href{https://github.com/XPixelGroup/BasicSR/tree/master/options}{option} 目录下。我们提供了常用模型的训练和测试配置文件。我们使用 \href{https://yaml.org/}{YAML} 来作为配置文件的语言。修改这些 yml 文件可以简易地调整训练过程中的各种超参数。详细说明参见章节\ref{code_structure:config}：\nameref{code_structure:config}和章节\ref{code_structure:register}：\nameref{code_structure:register}。

    \item 训练 (Training)：这一部分主要涉及训练的策略和记录训练日志。\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/train.py}{train.py} 和 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/test.py}{test.py} 是启动模型训练和测试的入口文件，其中定义了训练和测试的 main loop。常见优化器 (optimizer) 的定义可以在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{models/base\_model.py} 文件中的 \texttt{get\_optimizer} 函数中找到。学习率的调度策略在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{models/base\_model.py}  文件中的 \texttt{setup\_schedulers} 函数中定义。为了方便追踪记录训练的过程，我们提供了相应的 logger 工具，支持直接 print 到屏幕、Tensorboard、Wandb等多种方式，具体代码可以在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/logger.py}{utils/logger.py} 中找到。详细说明参见章节\ref{code_structure:training}：\nameref{code_structure:training}。\todo{本章节需要添加 training pipeline、logging 使用方式、test pipeline 的介绍。还有比如 logger 怎么用，validation 放在哪里、怎么用的内容。安排：logging 和 validation 放到 4.5 节 模型里面。training/testing pipeline 放到 4.7 节这里，和入门呼应、互补}

    \item 详细的代码接口文档可以在 \url{http://basicsr.readthedocs.io} 查询。
\end{itemize}

\begin{note} % ---------------- Note block ---------------- %
    \textbf{BasicSR 目录说明}

    你可以在章节\ref{getting_start:content-overview}：\nameref{getting_start:content-overview} 查看到详细的 BasicSR 目录说明。
\end{note}

% ------------------------------------------------------------------------------
\section{配置(Options)}\label{code_structure:config}

在这个章节，我们先简单介绍一下实验命名的约定 (第\ref{code_structure:name_convention}小节)；然后通过例子介绍训练和测试的配置文件 (第\ref{code_structure:config_example}小节)。

% ----------------------------------
\subsection{实验命名}\label{code_structure:name_convention}

我们推荐对实验名字进行有意义的命名，方便后续的实验以及进行多组实验对比。

我们以 \texttt{001\_MSRResNet\_x4\_f64b16\_DIV2K\_1000k\_B16G1\_wandb} 为例:

\begin{itemize}
    \item 001: 我们一般给实验进行数字打头的标号, 方便进行实验管理
    \item MSRResNet: 模型名称, 这里指代 Modified SRResNet
    \item x4\_f64b16: 重要配置参数, 这里表示放大4倍; 中间feature通道数是64, 使用了16个Residual Block
    \item DIV2K: 训练数据集是 DIV2K
    \item 1000k: 训练了1000K iterations
    \item B16G1: Batch size 为16, 使用一卡 GPU 训练
    \item wandb: 使用了 wandb, 训练过程上传到了 wandb 云服务器
\end{itemize}

\begin{hl} % ---------------- Highlight block ---------------- %
    \textbf{注意}

    如果在实验名字中有 \texttt{debug} 字样, 则会进入 debug 模式, 即程序会更密集地 log 和 validate, 并且不会使用 tensorboard logger 和 wandb logger。

    具体参见章节\ref{others:debug_mode}：\nameref{others:debug_mode}。
\end{hl}

% ----------------------------------
\subsection{配置文件简要说明}\label{code_structure:config_example}

在 BasicSR 中我们使用 \href{https://yaml.org/}{YAML} 来作为配置文件的语言。

训练的配置文件在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/options/train}{options/train} 中，测试的配置文件在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/options/test}{options/test} 中。
通过 option 配置文件，我们可以设置实验名、选择模型、指定 GPU、指定数据路径、选择网络结构、配置训练策略等。

我们在第\ref{code_structure:train_config}小节介绍训练配置文件例子，在第\ref{code_structure:test_config}小节介绍测试配置文件例子。

\todo{TODO：添加简要代码解析 - 如何从 YAML 文件解析。即分析 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/options.py}{basicsr/utils/options.py}}。

\subsubsection{训练配置文件例子}\label{code_structure:train_config}

下面，我们以 \href{https://github.com/XPixelGroup/BasicSR/blob/master/options/train/SRResNet_SRGAN/train_MSRResNet_x4.yml}{train\_MSRResNet\_x4.yml} 为例，简单说明训练配置文件的每个部分。我们先把配置文件贴出来，在后面附上解释。然后在说明框内会列举相关的要点。为方便说明，整个配置文件会被分散成不同的板块来讲解。

\begin{minted}[xleftmargin=20pt,breaklines,bgcolor=bg]{python}
# Modified SRResNet w/o BN from:
# Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network

# ----------- Commands for running
# ----------- Single GPU with auto_resume
# PYTHONPATH="./:${PYTHONPATH}"  CUDA_VISIBLE_DEVICES=0 python basicsr/train.py -opt options/train/SRResNet_SRGAN/train_MSRResNet_x4.yml --auto_resume

# general settings - 这块为通用设置
name: 001_MSRResNet_x4_f64b16_DIV2K_1000k_B16G1_wandb  # 实验名称, 若实验名字中有debug字样, 则会进入debug模式
model_type: SRModel  # 使用的 model 类型
scale: 4  # 输出比输入的倍数, 在SR中是放大倍数; 若有些任务没有这个配置, 则写1
num_gpu: 1  # 指定使用的 GPU 卡数
manual_seed: 0  # 指定随机种子
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{通用配置}
    \begin{itemize}
        \item 在配置文件的最开始，会有简单的说明，以及默认的运行命令。运行命令的 \texttt{auso\_resume} 表示自动从断点接着训练 (详见章节\ref{others:auto_resume}：\nameref{others:auto_resume})。
        \item 常见模型 (Model) 的定义在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/models}{models} 目录中。详细说明参见章节\ref{code_structure:model}：\nameref{code_structure:model}。
        \item \texttt{num\_gpu}：\textbf{0 表示 使用CPU，\texttt{auto} 表示自动从可用 GPU 块数推断}。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# dataset and data loader settings
datasets:  # 这块是 dataset 的配置
  train:  # 训练 dataset 的配置
    name: DIV2K  # 自定义的数据集名称
    type: PairedImageDataset  # 读取数据的 Dataset 类
    # 以下属性是灵活的, 可在相应类的说明文档中获得。新加的数据集可根据需要添加
    dataroot_gt: datasets/DF2K/DIV2K_train_HR_sub  #  GT (Ground-Truth) 图像的文件夹路径
    dataroot_lq: datasets/DF2K/DIV2K_train_LR_bicubic_X4_sub  # LQ (Low-Quality) 输入图像的文件夹路径
    meta_info_file: basicsr/data/meta_info/meta_info_DIV2K800sub_GT.txt  # 预先生成的 meta_info 文件
    # (for lmdb)
    # dataroot_gt: datasets/DIV2K/DIV2K_train_HR_sub.lmdb
    # dataroot_lq: datasets/DIV2K/DIV2K_train_LR_bicubic_X4_sub.lmdb
    filename_tmpl: '{}'  # 文件名字模板, 一般LQ文件会有类似 '_x4' 这样的文件后缀, 这个就是来处理GT和LQ文件后缀不匹配的问题的
    io_backend:  # IO 读取的 backend
      type: disk  # disk 表示直接从硬盘读取
      # (for lmdb)
      # type: lmdb

    gt_size: 128  # 训练阶段裁剪 (crop) 的GT图像的尺寸大小，即训练的 label 大小
    use_hflip: true  # 是否开启水平方向图像增强 (随机水平翻转图像)
    use_rot: true  # 是否开启旋转图像增强 (随机旋转图像)

    # data loader - 下面这块是 data loader 的设置
    num_worker_per_gpu: 6  # 每一个 GPU 的 data loader 读取进程数目
    batch_size_per_gpu: 16  # 每块 GPU 上的 batch size
    dataset_enlarge_ratio: 100  # 放大 dataset 的长度倍数 (默认为1)。可以扩大一个 epoch 所需 iterations
    prefetch_mode: ~  # 预先读取数据的方式
\end{minted}
\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{数据读取相关配置}
    \begin{itemize}
        \item 常见数据 (dataset) 的定义在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/data}{basicsr/data} 目录中。详细说明参见章节\ref{code_structure:data}：\nameref{code_structure:data}。
        \item data loader 定义在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/data/__init__.py}{basicsr/data/\_\_init\_\_.py} 文件中。
        \item meta\_info\_file：细节请参看章节\ref{data_preparation:meta_info}：\nameref{data_preparation:meta_info}。\todo{更新链接}
        \item io\_backend：细节请参看章节\ref{data_preparation:meta_info}：\nameref{data_preparation:meta_info}。\todo{更新链接}
        \item dataset\_enlarge\_ratio：详情参见章节\ref{code_structure:data}：\nameref{code_structure:data}。\todo{这块内容需要补足到 数据 这个章节}。
        \item prefetch\_mode:，\textbf{默认为 None，即 $\sim$。\texttt{cpu} 表示使用 CPU prefetcher。\texttt{cuda} 表示使用 CUDA prefetcher。它会多占用一些GPU显存. 注意: 这个模式下, 一定要设置 \texttt{pin\_memory=True}}。详情参见章节\ref{code_structure:data}：\nameref{code_structure:data}。\todo{这块内容需要补足到 数据 这个章节}
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
  val:  # validation 数据集的设置
    name: Set5  # 数据集名称
    type: PairedImageDataset  # 数据集的类型
    # 以下属性是灵活的, 类似训练数据集
    dataroot_gt: datasets/Set5/GTmod12
    dataroot_lq: datasets/Set5/LRbicx4
    io_backend:
      type: disk

  val_2:  # 另外一个 validation 数据集
    name: Set14
    type: PairedImageDataset
    dataroot_gt: datasets/Set14/GTmod12
    dataroot_lq: datasets/Set14/LRbicx4
    io_backend:
      type: disk
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{validation 配置}
    \begin{itemize}
        \item 这里使用了两个 validation sets，它们通过关键字 \texttt{val}，\texttt{val\_2} 来区分。如果有更多的 validation sets，可以通过 \texttt{val\_3}， \texttt{val\_4} ... 来区分。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# network structures - 网络结构的设置
network_g:  # 网络 g 的设置
  type: MSRResNet  # 网络结构 (Architecture) 的类型
  # 以下属性是灵活且特定的, 可在相应类的说明文档中获得
  num_in_ch: 3  # 模型输入的图像通道数
  num_out_ch: 3  # 模型输出的图像通道数
  num_feat: 64  # 模型内部的 feature map 通道数
  num_block: 16  # 模型内部基础模块的堆叠数
  upscale: 4  # 上采样倍数
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{网络结构相关配置}
    \begin{itemize}
        \item 常见网络结构 (arch) 的定义在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/archs}{archs} 目录下。详细说明参见章节\ref{code_structure:arch}：\nameref{code_structure:arch}。
        \item 如果模型需要使用多个网络，我们一般以 \texttt{network\_} 打头来命名。比如 我们需要一个 discriminator，命名为  \texttt{network\_d}。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# path
path:  # 以下为路径和与训练模型、重启训练的设置
  pretrain_network_g: ~  # 预训练模型的路径, 需要以 pth 结尾的模型
  param_key_g: params  # 读取的预训练的参数 key。若需要使用 EMA 模型，需要改成 params_ema
  strict_load_g: true  # 是否严格地根据参数名称一一对应 load 模型参数。如果选择 false，那么模型对于找不到的参数，会随机初始化；如果选择 true，假如存在不对应的参数，会报错提示
  resume_state: ~  # 重启训练的 state 路径, 在 experiments/exp_name/training_states 目录下
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{模型路径相关配置}
    \begin{itemize}
        \item resume\_state设置后, 会覆盖 pretrain\_network\_g 的设定
        \item ：对于 resume，更多信息可以参考章节\ref{others:auto_resume}：\nameref{others:auto_resume}。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# training settings
train:  # 这块是训练策略相关的配置
  ema_decay: 0.999  # EMA 更新权重
  optim_g:  # 这块是优化器的配置
    type: Adam  # 选择优化器类型，例如 Adam
    # 以下属性是灵活的, 根据不同优化器有不同的设置
    lr: !!float 2e-4  # 初始学习率
    weight_decay: 0  # 权重衰退参数
    betas: [0.9, 0.99]  # Adam 优化器的 beta1 和 beta2

  scheduler:  # 这块是学习率调度器的配置
    type: CosineAnnealingRestartLR   # 选择学习率更新策略
    # 以下属性是灵活的, 根据学习率 Scheduler 的不同有不同的设置
    periods: [250000, 250000, 250000, 250000]  # Cosine Annealing 的更新周期
    restart_weights: [1, 1, 1, 1]  # Cosine Annealing 每次 Restart 的权重
    eta_min: !!float 1e-7  # 学习率衰退到的最小值

  total_iter: 1000000  # 总共进行的训练迭代次数
  warmup_iter: -1  #  warm up 的迭代次数, 如是-1, 表示没有 warm up

  # losses - 这块是损失函数的设置
  pixel_opt:  # loss 名字，这里表示 pixel-wise loss 的 options
    type: L1Loss  # 选择 loss 函数，例如 L1Loss
    # 以下属性是灵活的, 根据不同损失函数有不同的设置
    loss_weight: 1.0  # 指定 loss 的权重
    reduction: mean  # loss reduction 方式
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{训练策略相关配置}

    训练策略相关的配置主要分为优化器，学习率调度器，总共训练 iterations，损失函数等。
    \begin{itemize}
        \item 关于 EMA，请参考章节\ref{others:ema}：\nameref{others:ema}。
        \item optim\_g，后缀 \texttt{\_g} 表示和 \texttt{network\_g} 中的 \texttt{\_g} 一一对应起来。
        \item \texttt{lr: !!float 2e-4} 中的 \texttt{!!float} 是 YAML 语言语法，表示以 float 解释后面的数字，不然就会以文字来进行解释。
        \item 常见优化器 (optimizer) 的定义可以在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{models/base\_model.py} 文件中的 \texttt{get\_optimizer} 函数中找到。
        \item 学习率的调度策略在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{models/base\_model.py}  文件中的 \texttt{setup\_schedulers} 函数中定义。
        \item 常用的损失函数可以在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/losses}{losses} 目录中定义。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# validation settings
val:  # 这块是 validation 的配置
  val_freq: !!float 5e3  # validation 频率, 每隔 5000 iterations 做一次 validation
  save_img: false  # 否需要在 validation 的时候保存图片

  metrics:  # 这块是 validation 中使用的指标的配置
    psnr:  # metric 名字, 这个名字可以是任意的
      type: calculate_psnr  # 选择指标类型
      # 以下属性是灵活的, 根据不同 metric 有不同的设置
      crop_border: 4  # 计算指标时 crop 图像边界像素范围 (不纳入计算范围)
      test_y_channel: false  # 是否转成在 Y(CbCr) 空间上计算
      better: higher  # 该指标是越高越好，还是越低越好。选择 higher 或者 lower，默认为 higher
    niqe:  # 这是在 validation 中使用的另外一个指标
      type: calculate_niqe
      crop_border: 4
      better: lower  # the lower, the better
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{validation 相关配置}
    \begin{itemize}
        \item 关于 metrics，请参考章节\ref{metrics:}：\nameref{metrics:}。\todo{更新}
        \item 指标在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/metrics}{basicsr/metrics} 目录中定义。
        \item BasicSR 支持在 validation 时使用多个指标，只需要在配置文件中添加配置，比如上面的 \texttt{psnr} 和 \texttt{niqe}。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# logging settings
logger:  # 这块是 logging 的配置
  print_freq: 100  # 多少次迭代打印一次训练信息
  save_checkpoint_freq: !!float 5e3  # 多少次迭代保存一次模型权重和训练状态
  use_tb_logger: true  # 是否使用 tensorboard logger
  wandb:  # 是否使用 wandb logger
    project: ~  #  wandb 的 project名字。 默认是 None, 即不使用 wandb
    resume_id: ~  # 如果是 resume, 可以输入上次的 wandb id, 则 log 可以接起来
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{训练日志相关配置}
    \begin{itemize}
        \item 关于 wandb，目前 wandb 只是同步 tensorboard 的内容, 因此要使用 wandb, 必须也同时使用 tensorboard。更多关于 wandb，参见章节\ref{metrics:}：\nameref{metrics:}。\todo{更新}。
    \end{itemize}
\end{exampleBox}

\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
# dist training settings
dist_params:  # distributed training 的设置, 目前只在 Slurm 训练下才需要
  backend: nccl
  port: 29500
\end{minted}

至此，我们对于训练的配置文件有了一个初步的理解了。

\subsubsection{测试配置文件例子}\label{code_structure:test_config}

我们以 \href{https://github.com/XPixelGroup/BasicSR/blob/master/options/test/SRResNet_SRGAN/test_MSRResNet_x4.yml}{test\_MSRResNet\_x4.yml} 为例，简单说明测试配置文件的每个部分。我们先把配置文件贴出来，在后面附上解释。然后在说明框内会列举相关的要点。为方便说明，整个配置文件会被分散成不同的板块来讲解。
由于测试配置文件和训练配置文件很类似，我们将简略地进行讲解。

\begin{minted}[xleftmargin=20pt,breaklines,bgcolor=bg]{python}
# ----------- Commands for running
# ----------- Single GPU
# PYTHONPATH="./:${PYTHONPATH}"  CUDA_VISIBLE_DEVICES=0 python basicsr/test.py -opt options/test/SRResNet_SRGAN/test_MSRResNet_x4.yml

# general settings
name: 001_MSRResNet_x4_f64b16_DIV2K_1000k_B16G1_wandb  # 实验名称
model_type: SRModel  # 使用的 model 类型
scale: 4  # 输出比输入的倍数, 在SR中是放大倍数; 若有些任务没有这个配置, 则写1
num_gpu: 1  # 测试卡数
manual_seed: 0  # 指定随机种子

# test dataset settings
datasets:
  test_1:  # 测试数据集的设置, 后缀1表示第一个测试集
    name: Set5  # 数据集的名称
    type: PairedImageDataset  # 读取数据的 Dataset 类
    # GT 和输入 LQ 的根目录
    dataroot_gt: datasets/Set5/GTmod12
    dataroot_lq: datasets/Set5/LRbicx4
    io_backend:  # IO 读取的 backend
      type: disk  # disk 表示直接从硬盘读取
  test_2:  # 测试数据集的设置, 后缀2表示第二个测试集
    name: Set14
    type: PairedImageDataset
    dataroot_gt: datasets/Set14/GTmod12
    dataroot_lq: datasets/Set14/LRbicx4
    io_backend:
      type: disk

# network structures - 网络结构的设置
network_g:  # 网络 g 的设置
  type: MSRResNet  # 网络结构 (Architecture) 的类型
  # 以下是 MSRResNet 的参数设置
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 64
  num_block: 16
  upscale: 4

# path
path:
  pretrain_network_g: experiments/001_..._wandb/models/net_g_1000000.pth  # 预训练模型的路径, 需要以 pth 结尾的模型
  param_key_g: params  # 读取的预训练的参数 key。若需要使用 EMA 模型，需要改成 params_ema
  strict_load_g: true  # 加载预训练模型时, 是否需要网络参数的名称严格对应

# validation settings - 以下为Validation (也是测试)的设置
val:
  save_img: true # 是否需要在测试的时候保存图片
  suffix: ~  # 对保存的图片添加后缀，如果是 None, 则使用 exp name

  metrics:  # 测试时候使用的 metric
    psnr:  # metric 名字, 这个名字可以是任意的
      type: calculate_psnr  # 选择指标类型
      # 以下属性是灵活的, 根据不同 metric 有不同的设置
      crop_border: 4  # 计算指标时 crop 图像边界像素范围 (不纳入计算范围)
      test_y_channel: false  # 是否转成在 Y(CbCr) 空间上计算
      better: higher  # the higher, the better. Default: higher
    ssim:  # 另外一个指标
      type: calculate_ssim
      crop_border: 4
      test_y_channel: false
      better: higher
\end{minted}

\begin{exampleBox}[righthand ratio=0.00, sidebyside, sidebyside align=center, lower separated=false]{注意}
    \begin{itemize}
        \item 如果模型训练的时候开启了 EMA，则在测试的时候需要指定 \texttt{param\_key\_g} 为 \texttt{params\_ema}。否则会出现测试和训练过程中 validation 不匹配的问题。
    \end{itemize}
\end{exampleBox}

至此，我们对于测试的配置文件有了一个初步的理解了。

% ------------------------------------------------------------------------------

\section{动态实例化与 REGISTER 注册机制}\label{code_structure:register}

% ----------------------------------
\subsection{REGISTER 注册机制}

首先，来看我们的目的：当我们新写了类 (Class) 或函数时，我们希望可直接在配置文件中指定，然后程序会根据配置文件的类名或函数名，自动查找并实例化。
以开发新的网络结构为例，我们会做以下几件事：
\begin{enumerate}
    \item 写具体的网络结构，它往往是一个Class，并且往往是一个单独的文件
    \item 在配置文件中会指定我们使用哪一个网络结构，往往是通过 Class name 指定
    \item 在训练过程的某一个地方，程序会根据配置文件指定的 Class name，自动实例化相关的类
\end{enumerate}

这里说的 REGISTER 注册机制就是来更简洁地实现上面的第三个步骤的。因为其能够根据配置文件动态地实例化所需要的类或函数，因此这个过程被称为动态实例化 (Dynamic Instantiation)。

BasicSR 的 Register 注册机制参考了 FacebookResearch 的 \href{https://github.com/facebookresearch/fvcore}{fvcore} 仓库的函数，定义了 Registry 类。详细代码可查看 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/registry.py}{basicsr/utils/registry.py}。它主要有两个函数：register() 和 get()。

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
class Registry():
    """
    The registry that provides name -> object mapping, to support third-party users' custom modules.
    """
    def __init__(self, name):
        self._name = name
        self._obj_map = {}

    def _do_register(self, name, obj, suffix=None):
        ...
        self._obj_map[name] = obj

    def register(self, obj=None, suffix=None):
        # register() 函数主要用来注册一个实现的类或函数
        if obj is None:
            # used as a decorator
            def deco(func_or_class):
                name = func_or_class.__name__
                self._do_register(name, func_or_class, suffix)
                return func_or_class

            return deco

        # used as a function call
        name = obj.__name__
        self._do_register(name, obj, suffix)

    def get(self, name, suffix='basicsr'):
        # get() 函数主要用来根据配置文件中的类名或函数名来查找对应的实例
        ret = self._obj_map.get(name)
        if ret is None:
            ret = self._obj_map.get(name + '_' + suffix)
        ...
        return ret
\end{minted}

\subsubsection{如何注册新的类？}

在 BasicSR 中，我们定义了五个 REGISTER ，相关定义在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/registry.py}{basicsr/utils/registry.py} 中：
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
DATASET_REGISTRY = Registry('dataset')
ARCH_REGISTRY = Registry('arch')
MODEL_REGISTRY = Registry('model')
LOSS_REGISTRY = Registry('loss')
METRIC_REGISTRY = Registry('metric')
\end{minted}

需要注册的时候，我们
\begin{enumerate}
    \item import 相关的注册器，比如 ARCH\_REGISTRY
    \item 使用 Python 装饰器，即在类/函数前面加上 \texttt{@ARCH\_REGISTRY.register()}
\end{enumerate}
这样 RRDBNet 这个类就被注册上啦。

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
from basicsr.utils.registry import ARCH_REGISTRY
from .arch_util import default_init_weights, make_layer, pixel_unshuffle

@ARCH_REGISTRY.register()
class RRDBNet(nn.Module):
    def __init__(self):
        super(RRDBNet, self).__init__()
        ...
\end{minted}



\subsubsection{如何使用已注册的类？}

当我们需要使用的时候，配置
它能有效解决上面提到的两个问题：

1、注册的时候，会强制检查有没有重名，减少了 bug 的产生。

2、只有在需要时，才会进行注册类或函数，其他中间量不会被注册。





其他的 DATASET，ARCH，MODEL，LOSS 都是类似的操作。它们都是注册了类，实例化的时候根据配置的 Class name 进行实例化。

注意，METRIC 稍微有点特殊，它是注册了函数，一样的用法，但是会根据函数名来调用相对应的函数。后面介绍 METRIC 的时候，再具体展开。

值得注意的是，即使我们使用了 REGISTER 机制，import 问题还是存在，即 Python 怎么知道你写了某个网络结构文件。

为了尽量少修改文件，我们沿用了动态实例化时候的做法，约定网络结构的文件使用  \_arch.py 结尾，然后自动扫描，import 进来。

其他的几个注册器的约定：

1、DATASET\_REGISTRY：以 \_dataset.py 结尾

2、ARCH\_REGISTRY：以 \_arch.py 结尾

3、MODEL\_REGISTRY：以 \_model.py 结尾

4、LOSS\_REGISTRY：以 \_loss.py 结尾 (目前只有一个文件，所以还没有添加相应的扫描的代码，后面会添加上)

5、METRIC\_REGISTRY: 这个因为改动很少，我们就保留了 在\_\_init\_\_.py 文件中 import 的方式:
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
from copy import deepcopy

from basicsr.utils.registry import METRIC_REGISTRY
from .niqe import calculate_niqe
from .psnr_ssim import calculate_psnr, calculate_ssim

__all__ = ['calculate_psnr', 'calculate_ssim', 'calculate_niqe']


def calculate_metric(data, opt):
    """Calculate metric from data and options.
    Args:
        opt (dict): Configuration. It must contain:
            type (str): Model type.
    """
    opt = deepcopy(opt)
    metric_type = opt.pop('type')
    metric = METRIC_REGISTRY.get(metric_type)(**data, **opt)
    return metric
\end{minted}

总结一下，当我们在新开发网络结构的时候，只要做两件事，修改两个文件就好了。BasicSR 背后的动态实例化和 REGISTRY 机制会帮你完成剩下的事。

1、写一个单独的网络结构文件 (以 \_arch.py 结尾)。在写好的 Class 前加上 @ARCH\_REGISTRY.register() 装饰器。

2、在配置文件中指定使用哪一个网络结构，即上面的 Class name。



1、无法避免重名的问题。一旦出现了类名重名，我们可能无法知道是否实例化了自己想要的类。2、该机制会把文件中所有的类、函数都 import 进来，十分冗余，因为很多类和函数都是中间的量。

具体而言，我们是通过importlib和getattr来实现的。以 data 为例，我们在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/data/__init__.py}{data/\_\_init\_\_.py} 中是如下做的:

1、扫描所有以 \_dataset.py 为结尾的文件 (这是约定)；

2、把这些文件中的类或函数通过 importlib 都 import 进来；

3、根据配置文件中的名称，通过 getattr 实例化。

具体操作的代码如下：

(读者只需知道这个机制即可，以下代码不影响 BasicSR 的直接使用)
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# automatically scan and import dataset modules
# scan all the files under the data folder with '_dataset' in file names
data_folder = osp.dirname(osp.abspath(__file__))
dataset_filenames = [
    osp.splitext(osp.basename(v))[0] for v in scandir(data_folder)
    if v.endswith('_dataset.py')
]
# import all the dataset modules
_dataset_modules = [
    importlib.import_module(f'basicsr.data.{file_name}')
    for file_name in dataset_filenames
]

...

# dynamic instantiation
for module in _dataset_modules:
    dataset_cls = getattr(module, dataset_type, None)
    if dataset_cls is not None:
        break
\end{minted}

我们对以下模块使用了类似的技巧，在使用的时候需要注意文件后缀名称的约定：
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Module} & \textbf{File Suffix} & \textbf{Example}                \\ \hline
        Data            & \_dataset.py         & data/paired\_image\_dataset.py  \\ \hline
        Model           & \_model.py           & basicsr/models/sr\_model.py     \\ \hline
        Archs           & \_arch.py            & basicsr/archs/srresnet\_arch.py \\ \hline
    \end{tabular}
    \caption{动态实例化文件命名约定}
\end{table}

\begin{hl} % ---------------- Highlight block ---------------- %
    \textbf{注意}

    1、上面的文件后缀只用在需要的文件中，其他文件命名尽量避免使用以上的后缀。

    2、类名或函数名不能重复。
\end{hl}

另外，对 losses 和 metrics，我们也使用了 importlib 和 getattr，但是和上面不一样的是，对于 losses 和 metrics，由于文件数量比较少，改动也少，因此我们不采用扫描文件的方式，而是在新增加类/函数后，需要在相应的 \_\_init\_\_.py 中增加类/函数名称。
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Module} & \textbf{Path}         & \textbf{Modify}                       \\ \hline
        Losses          & basicsr/models/losses & basicsr/models/losses/\_\_init\_\_.py \\ \hline
        Metrics         & basicsr/metrics       & basicsr/metrics/\_\_init\_\_.py       \\ \hline
        Archs           & \_arch.py             & basicsr/archs/srresnet\_arch.py       \\ \hline
    \end{tabular}
    \caption{部分类的实例化需要修改对应的 \_\_init\_\_.py 文件}
\end{table}

在 log 的时候, loss 项使用 l\_ 开头，这样在 Tensorboard 显示的时候，所有 loss 会被组织到一起。比如在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/srgan_model.py}{basicsr/models/srgan\_model.py} 中，使用了 l\_g\_pix，l\_g\_percep，l\_g\_gan 等。在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/logger.py}{basicsr/utils/logger.py} 中，他们会被组织到一起：
\begin{minted}[xleftmargin=20pt,bgcolor=bg,breaklines]{python}
if k.startswith('l_'):
    self.tb_logger.add_scalar(f'losses/{k}', v, current_iter)
else:
    self.tb_logger.add_scalar(k, v, current_iter)
\end{minted}

% ------------------------------------------------------------------------------
\section{数据 (Data Loader 和 Dataset)}\label{code_structure:data}

\subsection{Data loader 和 Dataset 的创建}\label{code_structure:dataloader_dataset}


\sebsection{Dataset 示例讲解}\label{code_structure:dataset_example}

包括文件夹的说明

\sebsection{Dataset prefetch 说明}\label{code_structure:dataset_example}

IO 加速

其他方法，

LMDB 格式加速，参见



数据是机器学习的动力来源。这一章节我们介绍 BasicSR 的数据读取和处理机制。在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/data}{basicsr/data/} 目录下，我们提供了常用的 Dataset 文件。

\dirtree{%
    .1 ROOT\_DIR.
    .2 BasicSR.
    .3 basicsr.
    .4 data.
    .5 \_\_init\_\_.py.
    .5 paired\_image\_dataset.py.
    .5 single\_image\_dataset.py.
    .5 realesrgan\_paired\_dataset.py.
    .5 realesrgan\_dataset.py.
    .5 reds\_dataset.py.
    .5 vimeo90k\_dataset.py.
    .5 video\_test\_dataset.py.
    .5 ffhq\_dataset.py.
    .5 data\_util.py.\DTcomment{提供了数据读取相关的函数}.
    .5 data\_sampler.py.
    .5 degradations.py.\DTcomment{提供若干图像退化的合成函数}.
    .5 prefetch\_dataloader.py.
    .5 transforms.py.\DTcomment{提供了常用的数据增强函数}.
}

BasicSR 提供的常用数据集的 Dataset 文件如下：

\begin{table}[h]
    \centering
    \resizebox{\textwidth}{26mm}{
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{类}              & \textbf{任务} & \textbf{训练/测试} & \textbf{描述}                                          \\ \hline
            PairedImageDataset       & 图像超分      & 训练               & 读取成对的训练数据                                     \\ \hline
            SingleImageDataset       & 图像超分      & 测试               & 只读取 low quality 的图像, 用于没有 GT 的测试中        \\ \hline
            REDSDataset              & 视频超分      & 训练               & 读取 REDS 的训练数据集                                 \\ \hline
            Vimeo90KDataset          & 视频超分      & 训练               & 读取 Vimeo90K 的训练数据集                             \\ \hline
            VideoTestDataset         & 视频超分      & 测试               & 基础的视频超分测试集, 支持 Vid4,  REDS 测试集          \\ \hline
            VideoTestVimeo90KDataset & 视频超分      & 测试               & 继承 VideoTestDataset；Vimeo90K 的测试数据集           \\ \hline
            VideoTestDUFDataset      & 视频超分      & 测试               & 继承 VideoTestDataset； DUF算法的测试数据集, 支持 Vid4 \\ \hline
            FFHQDataset              & 人脸生成      & 训练               & 读取 FFHQ 的训练数据集                                 \\ \hline
        \end{tabular}
    }
    \caption{BasicSR 提供的数据处理类}
\end{table}

下面，我们以 PairedImageDataset 为例，大致讲解 Dataset 文件的内容。
\begin{minted}[xleftmargin=20pt,linenos,breaklines,bgcolor=bg,breaklines]{python}
    @DATASET_REGISTRY.register()
    class PairedImageDataset(data.Dataset):
        def __init__(self, opt):
            super(PairedImageDataset, self).__init__()
            self.opt = opt
            # file client (io backend)
            self.file_client = None
            self.io_backend_opt = opt['io_backend']
            self.mean = opt['mean'] if 'mean' in opt else None
            self.std = opt['std'] if 'std' in opt else None
    \end{minted}

在 option 文件中可以指定数据读取方式 (opt['io\_backend'])。

我们支持三种读取数据的模式：

1、直接从 lmdb 格式的文件中读取；

2、若提供了 meta\_info 文件，则直接从该文件中列出的文件路径读取数据；

3、输入文件目录，代码会自动扫描该目录中的文件，然后读取。


\begin{minted}[xleftmargin=20pt,linenos,breaklines,bgcolor=bg]{python}
            self.gt_folder, self.lq_folder = opt['dataroot_gt'], opt['dataroot_lq']
            if 'filename_tmpl' in opt:
                self.filename_tmpl = opt['filename_tmpl']
            else:
                self.filename_tmpl = '{}'

            if self.io_backend_opt['type'] == 'lmdb':
                self.io_backend_opt['db_paths'] = [self.lq_folder, self.gt_folder]
                self.io_backend_opt['client_keys'] = ['lq', 'gt']
                self.paths = paired_paths_from_lmdb([self.lq_folder, self.gt_folder], ['lq', 'gt'])
            elif 'meta_info_file' in self.opt and self.opt['meta_info_file'] is not None:
                self.paths = paired_paths_from_meta_info_file([self.lq_folder, self.gt_folder], ['lq', 'gt'], self.opt['meta_info_file'], self.filename_tmpl)
            else:
                self.paths = paired_paths_from_folder([self.lq_folder, self.gt_folder], ['lq', 'gt'], self.filename_tmpl)
    \end{minted}

从 option 文件中读取 GT 图像目录 (opt['dataroot\_gt']) 和输入图像目录 (opt['dataroot\_lq'])。

根据指定的文件读取方式，选择相应的读取函数。

1、lmdb 方式， 选择 paired\_paths\_from\_lmdb 函数;

2、meta\_info\_file 方式，选择 paired\_paths\_from\_meta\_info\_file 函数；

3、一般的文件目录方式，选择 paired\_paths\_from\_folder 函数。

\begin{minted}[xleftmargin=20pt,linenos,breaklines,bgcolor=bg]{python}
        def __getitem__(self, index):
            if self.file_client is None:
                self.file_client = FileClient(self.io_backend_opt.pop('type'), **self.io_backend_opt)

            scale = self.opt['scale']

            # Load gt and lq images. Dimension order: HWC; channel order: BGR;
            # image range: [0, 1], float32.
            gt_path = self.paths[index]['gt_path']
            img_bytes = self.file_client.get(gt_path, 'gt')
            img_gt = imfrombytes(img_bytes, float32=True)
            lq_path = self.paths[index]['lq_path']
            img_bytes = self.file_client.get(lq_path, 'lq')
            img_lq = imfrombytes(img_bytes, float32=True)
    \end{minted}

\_\_getitem\_\_() 函数是 Dataset 中最关键的函数，定义了每一次迭代时数据是如何读取并处理的。 图像通过 FileClient 读取后，shape 为 HWC， 其中颜色通道的排列顺序为 BGR。图像此时为 [0, 1] 的 float32 格式。

\begin{minted}[xleftmargin=20pt,linenos,breaklines,bgcolor=bg]{python}
            # augmentation for training
            if self.opt['phase'] == 'train':
                gt_size = self.opt['gt_size']
                # random crop
                img_gt, img_lq = paired_random_crop(img_gt, img_lq, gt_size, scale, gt_path)
                # flip, rotation
                img_gt, img_lq = augment([img_gt, img_lq], self.opt['use_hflip'], self.opt['use_rot'])

            # color space transform
            if 'color' in self.opt and self.opt['color'] == 'y':
                img_gt = rgb2ycbcr(img_gt, y_only=True)[..., None]
                img_lq = rgb2ycbcr(img_lq, y_only=True)[..., None]
    \end{minted}

这一部分首先对读取的图像进行 crop 处理 (从原图中随机 crop 出一个 patch)，然后进行随机的水平翻转和旋转，进行数据增强。如果要使用单通道训练 (YCbCR 颜色空间中的 Y 通道)，代码会对 GT 和 input 进行颜色转换。

\begin{minted}[xleftmargin=20pt,linenos,breaklines,bgcolor=bg]{python}
            # crop the unmatched GT images during validation or testing, especially for SR benchmark datasets
            if self.opt['phase'] != 'train':
                img_gt = img_gt[0:img_lq.shape[0] * scale, 0:img_lq.shape[1] * scale, :]

            # BGR to RGB, HWC to CHW, numpy to tensor
            img_gt, img_lq = img2tensor([img_gt, img_lq], bgr2rgb=True, float32=True)
            # normalize
            if self.mean is not None or self.std is not None:
                normalize(img_lq, self.mean, self.std, inplace=True)
                normalize(img_gt, self.mean, self.std, inplace=True)

            return {'lq': img_lq, 'gt': img_gt, 'lq_path': lq_path, 'gt_path': gt_path}
    \end{minted}

在测试时，由于上下采样的原因，有时候模型的输出和原始的图像大小会出现不匹配的情况。例如，原始图像大小为 $530 \times 530$，在 $\times 4$  超分中，原图会下采样变成 $132 \times 132$ 的输入，模型会超分后会得到 $528 \times 528$ 的输出，与原图大小不匹配，进而无法直接计算 PSNR 等指标。于是，为了避免这个问题，我们在测试时，会 crop 原始图像多余的像素，使其分辨率和模型输出相同。

另外，我们对图像格式进行一些转换：把 BGR 格式转换为 RGB；把 HWC 的排列，转换为 Pytorch所需的 CHW。如果指定了数据集的均值 (mean) 和标准差 (std)，我们将会进一步对数据进行Z-score标准化操作。

最后，我们返回一个字典，包括输入的 LQ 图像，作为标签的 GT 图像，以及他们的路径。

% ------------------------------------------------------------------------------

\section{网络结构 (Architecture)} \label{code_structure:arch}
在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/archs}{basicsr/archs/} 目录下，我们提供了若干经典的网络结构。

\begin{table}[h]
    \centering
    {
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{网络结构} & \textbf{任务} & \textbf{文件}          & \textbf{描述}                          \\ \hline
            EDSR              & 图像超分      & edsr\_arch.py          & 论文EDSR结构                           \\ \hline
            SRResNet          & 图像超分      & srresnet\_arch.py      & 论文SRGAN的Generator                   \\ \hline
            RRDB              & 图像超分      & rrdbnet\_arch.py       & 论文ESRGAN的Generator                  \\ \hline
            RCAN              & 图像超分      & rcan\_arch.py          & 论文RCAN的结构                         \\ \hline
            SwinIR            & 图像超分      & swinir\_arch.py        & 论文SwinIR的结构                       \\ \hline
            ECBSR             & 图像超分      & ecbsr\_arch.py         & 论文ECBSR的结构                        \\ \hline
            SRVGG             & 图像超分      & srvgg\_arch.py         & VGG结构改造的SR网络                    \\ \hline
            EDVR              & 视频超分      & edvr\_arch.py          & 论文EDVR的结构                         \\ \hline
            BasicVSR          & 视频超分      & basicvsr\_arch.py      & 论文BasicVSR的结构                     \\ \hline
            BasicVSR++        & 视频超分      & basicvsrpp\_arch.py    & 论文BasicVSR++的结构                   \\ \hline
            DUF               & 视频超分      & duf\_arch.py           & 论文DUF的结构                          \\ \hline
            TOF               & 视频超分      & tof\_arch.py           & 论文TOF的结构                          \\ \hline
            HiFaceGAN         & 人脸生成      & hifacegan\_arch.py     & 论文HiFaceGAN的结构                    \\ \hline
            DFDNet            & 人脸生成      & dfdnet\_arch.py        & 论文Deep Face Dictionary Network的结构 \\ \hline
            StyleGAN2         & 人脸生成      & stylegan2\_arch.py     & 论文StyleGAN2的结构                    \\ \hline
            RIDNet            & 图像去噪      & ridnet\_arch\_arch.py  & 论文RIDNet的结构                       \\ \hline
            VGG               & 工具结构      & vgg\_arch.py           & 经典VGG结构                            \\ \hline
            InceptionV3       & 工具结构      & inception.py           & 经典InceptionV3的结构，用于计算FID指标 \\ \hline
            VGG \& UNet       & 工具结构      & discriminator\_arch.py & 在GAN训练中，常用的Discriminator结构   \\ \hline
            SpyNet            & 工具结构      & spynet\_arch.py        & 论文SpyNet的结构                       \\ \hline
        \end{tabular}
    }
    \caption{BasicSR 提供的经典网络结构}
\end{table}

% ------------------------------------------------------------------------------

\section{模型 (Model)}\label{code_structure:model}


\todo{添加 resume 和保存文件     训练的时候， checkpoints 会保存两个文件：1）网络参数 .pth 文件；2）包含 optimizer 和 scheduler 的信息 .state 文件。根据这两个文件，则可以 resume 了。 resume 就是把最新的 .pth 和 .resume 文件正确load进来。详细的函数在 basicsr/train.py 的 load\_resume\_state 函数中。我后面也会具体写文章再介绍。下面这个截图就是模型训练过程中会保存的文件 models 和 training\_states  。}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.7\linewidth]{figures/getting_start_4.png}
        \caption{模型训练过程中会保存的 models 和 training\_states 文件}
        \label{fig:getting_start_4}
    \end{center}
    \vspace{-0.5cm}
\end{figure}

模型部分定义了许多模型级别的操作，比如训练设置、训练数据如何送入模型、优化器的选择、损失函数计算、模型参数更新、训练中验证、测试过程等。模型部分定义在：
\dirtree{%
    .1 ROOT\_DIR.
    .2 BasicSR.
    .3 basicsr.
    .4 models.
    .5 \_\_init\_\_.py.\DTcomment{扫描所有models并注册，实例化某模型}.
    .5 base\_model.py\DTcomment{模型的基类，定义许多共同操作}.
    .5 edvr\_model.py.
    .5 esrgan\_model.py.
    .5 hifacegan\_model.py.
    .5 realesrgan\_model.py.
    .5 realesrnet\_model.py.
    .5 sr\_model.py\DTcomment{图像超分模型}.
    .5 srgan\_model.py.
    .5 stylegan2\_model.py.
    .5 swinir\_model.py.
    .5 video\_base\_model.py\DTcomment{视频超分基类模型}.
    .5 video\_gan\_model.py.
    .5 video\_recurrent\_gan\_model.py.
    .5 video\_recurrent\_model.py.
}

其中 \_\_init\_\_.py 会自动扫描 basicsr/models 中的文件，如果是以 \_model.py 结尾的，则为其中注册器中的模型进行 import 。然后根据 option 中的 model\_type 实例化对应模型并返回。

\begin{note} % ---------------- Note block ---------------- %
    注册器参见章节\ref{Register}。
\end{note}

为增加模型间的复用, 我们大量使用了继承, 以下为各个模型之间的继承关系:

\dirtree{%
    .1 Base\_Model.
    .2 SR\_Model.
    .3 SRGAN\_Model.
    .4 ESRGAN\_Model.
    .4 RealESRGAN\_Model.
    .3 RealESRNet\_Model.
    .3 SwinIR\_Model.
    .3 Video\_Base\_Model.
    .4 EDVR\_Model.
    .4 VideoRecurrent\_Model.
    .5 VideoRecurrentGAN\_Model.
    .3 HiFaceGAN\_Model.
    .2 StyleGAN2\_Model.
}

下面具体介绍一些重要模型及其功能，以及如何按照自己的需求自定义新的模型。

\subsection{Base Model}
Base Model是所有模型的基类，定义一些共同操作。比如：

代码位置：\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{BasicSR/basicsr/models/base\_model.py}
\begin{minted}[xleftmargin=20pt,breaklines,linenos,bgcolor=bg]{python}

def print_network(self, net):
# 输出网络信息

def save_network(self, net, net_label, current_iter, param_key='params'):
# 保存模型

def save_training_state(self, epoch, current_iter):
# 保存训练状态

def load_network(self, net, load_path, strict=True, param_key='params'):
# 加载模型

def get_optimizer(self, optim_type, params, lr, **kwargs):
# 定义优化器

def _get__init__lr(self):
# 定义初始学习率

def update_learning_rate(self, current_iter, warmup_iter=-1):
# 学习率更新

def setup_schedulers(self):
# 学习率调度器
\end{minted}

\begin{hl} % ---------------- Highlight block ---------------- %
    Base Model 的很多函数，可以在继承后的模型中根据要求来重写，比如不同模型读取数据的方式不同，则会重写不同的 feed\_data() 函数。
\end{hl}

\subsection{其他模型，以 SR Model 为例}\label{Model:SR Model}

SR Model 是图像超分辨率模型的类，定义了基础的单张图像超分辨率模型。下面从一个模型的训练角度展示其中重要的函数：

代码位置：\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/sr_model.py}{BasicSR/basicsr/models/sr\_model.py}

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}

class SRModel(BaseModel):
    """Base SR model for single image super-resolution."""

    def ___init___(self, opt):

    def init_training_settings(self):
    # 初始化训练设置。包括优化器、损失函数的定义，学习率的初始化等。

    def setup_optimizers(self):
    # 设置优化器，可以控制哪些参数会被更新。详情参阅4.7优化器部分。

    def feed_data(self, data):
    # 把训练数据送入模型。这里是从 dataloader 中取出数据，用于训练或测试。在 SR Model 中，每次取用一个 batch(n,c,h,w) 数量的 LR 和 GT 图像。

    # 其他模型对batch做不同操作时，经常会改写这个函数。比如只读取 GT 、读取额外 label 、读取图像路径、对读取的数据增加 degradation 等操作，都通过修改 feed\_data() 来实现。

    def optimize_parameters(self, current_iter):
    # 更新模型参数。在这个函数中，会实际调用模型跑出 SR 图像，再将 SR 与 GT 代入损失函数计算 loss，并且进行 loss 的回传和参数的更新。当有多个 loss 或需要自己添加 loss 时，或者需要特殊的更新步骤时，修改这里。

    # 比如在 GAN 系列的 Model 中，这个函数就是 SR 图像与 GT 一起输入判别网络来得到 loss ，再将不同的 loss 进行加权组合。并且 Generator 和 Discriminator 的参数都需要更新。

    def nondist_validation(self, dataloader, current_iter, ...):
    # 训练中进行验证。会停止训练，调用 test() ，进行验证并记录指标、保存结果图，然后继续训练。

    def get_current_visuals(self):
    # 将当前图片从 GPU 中取出，以进行保存或其它操作。

    def save(self, epoch, current_iter):
    # 保存模型。
\end{minted}

其他model的思想与SR Model大同小异，都是相互继承公用的函数，单独改写有特别需求的函数，完成一个模型包括获得数据、更新参数、验证等步骤的训练过程。


\subsection{自定义模型，以 SRGAN Model 为例}

当需要自定义某个模型的时候，首先在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models}{BasicSR/basicsr/models} 下新建 XXX\_model.py 文件，根据需要写一个新类（注意不要与现有类重名）继承 Base Model 或其他 model ，然后根据自己的需求改写主要函数即可。

比如 SRGAN\_Model 继承了绝大多数 SR\_Model 的函数，但是改写了 optimize\_parameters() ，适应 GAN 的参数更新需要。而 RealSRGAN\_Model 又继承了 SRGAN\_Model ，改写了 feed\_data() 以在线生成带有不同 degradation 的训练数据。

\begin{note} % ---------------- Note block ---------------- %
    上述被改写函数的介绍，参见章节\ref{Model:SR Model}。
\end{note}

% ------------------------------------------------------------------------------

\section{损失函数 (Loss)}\label{code_structure:loss}

损失函数部分定义了很多常用的损失函数。损失函数部分定义在：
\dirtree{%
    .1 ROOT\_DIR.
    .2 BasicSR.
    .3 basicsr.
    .4 losses.
    .5 \_\_init\_\_.py.\DTcomment{扫描所有 loss 并注册，实例化某些损失函数}.
    .5 losses.py.\DTcomment{损失函数的具体实现}.
    .5 loss\_util.py.\DTcomment{损失函数工具，如对损失函数加权、累加、平均等}.
}
\subsection{损失函数的使用}

损失函数主要在不同 model 里被定义、计算和使用。下面是一个例子。

代码位置：\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/sr_model.py}{BasicSR/basicsr/models/sr\_model.py}，其他 model 文件中也有。

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}

def init_training_settings(self):
    ……
    self.cri_pix = build_loss(train_opt['pixel_opt']).to(self.device)
    # 定义损失函数


def optimize_parameters(self, current_iter):
    self.optimizer_g.zero_grad()
    # 优化器梯度归零

    l_pix = self.cri_pix(self.output, self.gt)
    # 在更新参数时，需要计算 loss
    l_total += l_pix
    loss_dict['l_pix'] = l_pix
    # 将 loss 记录到 log 文件里

    l_total.backward()
    # loss 反向传播，计算梯度

    self.optimizer_g.step()
    # 更新网络参数
\end{minted}

\subsection{自定义损失函数}

在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/losses/losses.py}{BasicSR/basicsr/losses/losses.py} 下写一个新的损失函数类，并将类名写入\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/losses/__init__.py}{BasicSR/basicsr/losses/\_\_init\_\_.py}。可以参考其他损失函数类的写法，对一个 batch 的数据进行计算并返回 loss 的值。


% ------------------------------------------------------------------------------

\section{训练[优化器 (optimizer) 与学习率调度器 (scheduler) ]}\label{code_structure:training}

\begin{note} % ---------------- Note block ---------------- %
    训练的整体pipeline参见\ref{}。
\end{note}

本节主要介绍其中的优化器、优化步骤和学习率调度相关内容。当训练进行到更新模型参数时，即
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
model.optimize_parameters(current_iter) # 在BasicSR/basicsr/train.py
\end{minted}

模型会运行得到结果、计算loss并根据优化器进行参数优化，然后更新学习率。

这个步骤的具体代码定义在BasicSR/basicsr/models中具体的Model里，因为需要计算的loss的步骤是各不相同的，比如GAN需要经过判别器。

代码位置：\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/sr_model.py}{BasicSR/basicsr/models/sr\_model.py}，其他 model 文件中也有。

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}

def optimize_parameters(self, current_iter):
    self.optimizer_g.zero_grad()
    # 优化器梯度归零

    # 计算loss，代码省略

    l_total.backward()
    # loss反向传播，计算梯度

    self.optimizer_g.step()
    # 更新网络参数
\end{minted}

此时，optimizer 就会去更新参数。 optimizer 在 init\_training\_setting 中定义，定义的时候，会定义好哪些参数需要更新、按照什么样的方法去更新（优化方法）。

代码位置：\href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/sr_model.py}{BasicSR/basicsr/models/sr\_model.py}，其他 model 文件中也有。

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}

def setup_optimizers(self):
    train_opt = self.opt['train']
    optim_params = []
    for k, v in self.net_g.named_parameters():
        # 对于网络中的所有需要梯度的参数，添加进优化器中。
        # 这里可以按照结构名称，来规定哪些参数需要使用当前优化器更新。
        if v.requires_grad:
            optim_params.append(v)
        else:
            logger = get_root_logger()
            logger.warning(f'Params {k} will not be optimized.')

    optim_type = train_opt['optim_g'].pop('type')
    # 这里定义优化器的优化方法，如Adam
    self.optimizer_g = self.get_optimizer(...)
    self.optimizers.append(self.optimizer_g)
    # 把当前这个优化器放到optimizers里面，也就是说可以定义多个优化器去优化同一网络的不同参数部分。
\end{minted}

而优化器更新参数时的学习率，来源于学习率调度器 scheduler。 scheduler 同样在 init\_training\_setting 中定义。学习率更新时，就是调用 scheduler ，来生成当前需要的学习率。代码在 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/models/base_model.py}{BasicSR/basicsr/models/base\_model.py} 中：

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}

def setup_schedulers(self):
    # 选择scheduler类型，比如训练多少次迭代后，学习率衰减（MultiStepLR）。
\end{minted}



% ------------------------------------------------------------------------------

\section{算子 (Ops)}\label{code_structure:ops}

\subsection{什么是算子？}

当使用pytorch时，绝大多数操作为张量 (Tensor) 的运算。张量计算的种类有很多，比如加法、乘法、矩阵相乘、矩阵转置等，这些计算被称为算子 (Operator)，它们是PyTorch的核心组件。

一般情况下，pytorch推荐使用python层的前端语言来构建新的算子。但是有时候出于一些其他方面的考虑，会需要增加底层算子。例如有时候对性能要求很高，python不满足需求，又或者是需要链接其他的动态库(blas，mkl等)，因此pytorch也提供了直接扩展底层C++算子的能力。

\subsection{BasicSR 中的自定义算子}

BasicSR中所用的自定义算子代码在 \href{https://github.com/XPixelGroup/BasicSR/tree/master/basicsr/ops}{BasicSR/basicsr/ops} 中。采用C++ extension的方式添加。它与pytorch的相互解耦，分开编译，所以增加算子不需要修改pytorh的源码。它的原理其实就是通过pybind11，将C++编译为pytroch的一个模块，这样就可以在pytorch中通过这个新的模块来执行新的操作了。添加方法详情参阅 \href{https://pytorch.org/tutorials/advanced/cpp_extension.html#writing-a-mixed-c-cuda-extension}{pytorch官方文档} 。

BasicSR中的自定义算子主要有deform\_conv，upfirdn2d，fused\_act三大类。deform\_conv主要用在各个视频恢复的模型上，是一种隐式的对齐方式。upfirdn2d，fused\_act，用在stylegan2中。

\subsection{BasicSR 中算子的编译、安装、使用}

\begin{note} % ---------------- Note block ---------------- %
    编译和安装的过程参见\ref{Register}。
\end{note}

当算子成功编译之后，调用自定义算子就像调用pytorch原生算子一样。


\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# 调用pytorch原生算子
from torch import nn

Class xxx():
    def __init__():
        conv1 = nn.Conv2d(……)

    def forward():
        out = conv1(……)

# 调用自定义算子，可以直接在forward中使用
from basicsr.ops.upfirdn2d import upfirdn2d

    def forward():
        out = upfirdn2d(……)

\end{minted}

% ------------------------------------------------------------------------------

\section{日志系统 (Logger)} \label{code_structure:logger}

BasicSR 的日志系统主要包括实验过程中1.记录的 log 文件和2.可以通过 tensorboard 可视化的 tb\_logger。

日志系统的实现不过多赘述，如果有兴趣可以参阅 \href{https://github.com/XPixelGroup/BasicSR/blob/master/basicsr/utils/logger.py}{BasicSR/basicsr/utils/logger.py}。本章节主要讲述日志系统各个项目代表什么；以及如何改代码，在日志中记录我们想记录的个性化内容。

\subsection{log 文件记录及解读}

当进行实验的时候，代码会在 BasicSR/experiments 中创建一个属于当前实验的文件夹，文件夹名字为实验名，文件夹中会存在一个 log 文件，下面我们来说明如何按照我们自己的要求记录 log 文件，以及现有 log 文件每个条目的意义。

\begin{hl} % ---------------- Highlight block ---------------- %

    添加一条 log 信息非常简单：

    \begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
logger.info(要添加的内容) # 添加正常信息
logger.warning(要添加的警告) # 添加警告信息
\end{minted}
\end{hl}

在 model 文件中，已经定义好 logger 的情况下，只要在合适的位置添加上述语句，即可记录信息。每个 model 文件中都有大量的 logger 添加，故不具体展示使用位置，有兴趣的读者可以自己在 model 文件中搜索。

log 文件是 \texttt{train\_[exp\_name]\_[timestamp].log} 的命名方式

下面是一个 log 文件的例子：

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.7\linewidth]{figures/getting_start_6.png}
        \caption{实验过程中产生的 log 信息}
        \label{fig:getting_start_6}
    \end{center}
    \vspace{-0.5cm}
\end{figure}

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# log 文件所在位置: experiments/实验名字/train_[exp_name]_[timestamp].log
2022-06-17 02:27:36,068 INFO:
# 在代码中调用 logger.info()后，会自动记录时间并增加条目 INFO:
# 为节省篇幅，下面 log 中删掉了时间信息

Version Information:
# 软件的版本
    BasicSR: 1.3.3.10
    PyTorch: 1.9.1+cu111
    TorchVision: 0.10.1+cu111
INFO:
  name: 000_SRResNet_DIV2K
  # 实验名，整个options的内容都会记录在这里，本文件中省略掉了。


INFO: Dataset [XXXDataset] - XXXdata is built.
INFO: Training statistics:
# 训练数据的信息，数量、batchsize等
    Number of train images: 38684
    Dataset enlarge ratio: 1
    Batch size per gpu: 16
    World size (gpu number): 1
    Require iter number per epoch: 2418
    Total epochs: 207; iters: 500000.
INFO: Dataset [PairedImageDataset] - validation is built.
# dataset类型
INFO: Number of val images/folders in validation: 14
# 验证集信息
INFO: Network [MSRResNet] is created.
INFO: Network: MSRResNet, with parameters: 1,222,147
# 网络参数量
INFO: MSRResNet(
# 网络结构，此处省略

INFO: Use Exponential Moving Average with decay: 0.999
INFO: Loss [L1Loss] is created.
INFO: Model [RealESRNetModel_XXX] is created.
INFO: Start training from epoch: 0, iter: 0
# 开始训练
INFO: [XXX_0..][epoch:  0, iter:     100, lr:(2.000e-04,)] [eta: 2 days, 21:55:41, time (data): 0.040 (0.004)] l_pix: 5.0581e-02
# epoch:第几轮；iter:第几次迭代（一次迭代是一个batch）, lr:学习率][eta：剩余时间预估 time (data):跑了百分之多少的数据了] l_pix:当前的loss
INFO: Validation validation
# 验证集验证结果
     #  psnr: 18.0289

INFO: End of training. Time consumed: 10:22:17
INFO: Save the latest model.
INFO: Validation validation
# 训练结束，最终验证集结果
     #  psnr: 20.7466

\end{minted}

\subsection{tb\_logger 记录及解读}

除了上述的 log 文件外，BasicSR 还会生成可以用 tensorboard 打开的 tb\_logger 文件。一般保存在 BasicSR/experiments/tb\_logger/ 实验名。


开启: 在 yml 配置文件中设置 `use\_tb\_logger: true`:
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# yml
    logger:
      use_tb_logger: true
\end{minted}

在浏览器中查看：
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# bash
    tensorboard --logdir tb_logger --port 5500 --bind_all
\end{minted}

\begin{figure}[h]
    %\vspace{-0.5cm}
    \begin{center}
        %\fbox{\rule{0pt}{2.5in} \rule{0.9\linewidth}{0pt}}
        \includegraphics[width=0.8\linewidth]{figures/tensorboard_demo.png}
        % \vspace{-1cm}
        \caption{tensorboard示例图}
        \label{fig:tensorboard_demo}
    \end{center}
    %\vspace{-0.7cm}
\end{figure}

目前 BasicSR 里 tb\_logger 主要记录 validation 结果和训练过程中的 loss。validation 结果会随增加 metric 而增加，不过多赘述，重点介绍如何添加 loss 记录到 tb\_logger 。

\begin{hl} % ---------------- Highlight block ---------------- %
    虽说封装的很深，但是实际在框架中使用起来，只需要在 xx\_model.py 计算 loss 之后，把新的 loss， loss\_dict['新的loss'] = 新的loss ，即可同时记录在 tb\_logger 和 los 文件中。
    也可以使用这种方法记录不是 loss 的其他值。
\end{hl}

下面介绍具体的封装细节，tb\_logger 的初始化和记录代码为：

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
tb_logger.add_scalar(f'metrics/{metric}', value, current_iter)
# 这个是记录validation结果的。
\end{minted}

一个上述语句封装的例子：

\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
# BasicSR/basicsr/train.py中：

    tb_logger = init_tb_loggers(opt)
    # 初始化tb_logger
    msg_logger = MessageLogger(opt, current_iter, tb_logger)
    # 实例化msg_logger，包含了tb_logger
    ……
    log_vars.update(model.get_current_log())
    # 更新log_vars
    msg_logger(log_vars)
    # 调用messagelogger

# BasicSR/basicsr/utils/logger.py中定义了MessageLogger类：

    class MessageLogger():
        ……
        def __call__(self, log_vars):
            ……
            self.tb_logger.add_scalar(f'losses/{k}', v, current_iter)
            # 这里调用了添加tb_logger

# BasicSR/basicsr/models/base_model.py中定义了get_current_log()：

    def get_current_log(self):
        return self.log_dict

# self.log_dict在BasicSR/basicsr/models/sr_model.py中：

    loss_dict['l_pix'] = l_pix
    self.log_dict = self.reduce_loss_dict(loss_dict)
\end{minted}


\subsection{Wandb 记录及解读}

\href{https://www.wandb.com/}{wandb} 类似tensorboard的云端版本, 可以在浏览器方便地查看模型训练的过程和曲线。我们目前只是把tensorboard的内容同步到wandb上, 因此要使用wandb, 必须打开tensorboard logger，参见上一节。\href{https://wandb.ai/xintao/basicsr?workspace=user-}{BasicSR wandb示例}

配置文件如下:
\begin{minted}[xleftmargin=20pt,linenos,bgcolor=bg,breaklines]{python}
yml
logger:
  # 是否使用tensorboard logger
  use_tb_logger: true
  # 是否使用wandb logger,目前wandb只是同步tensorboard的内容,因此要使用wandb, 必须也同时使用tensorboard
  wandb:
    # wandb的project. 默认是 None, 即不使用wandb.
    # 这里使用了 basicsr wandb project: https://app.wandb.ai/xintao/basicsr project: basicsr
    # 如果是resume, 可以输入上次的wandb id, 则log可以接起来
    resume_id: ~
\end{minted}

\end{document}
